geom_point(aes(fill=fit),main_plot, alpha = 1,shape = 21, colour = "black",size=2) +
#coord_fixed() +
facet_grid(~training_length) +
scale_x_continuous(breaks = breaks_extended(6)) +
xlab('Average # entries per session')+
ylab('Average # sessions per day')
pp <- p + theme_minimal(base_size = 14, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 16, face = "bold"),
strip.text.y = element_text(size = 16, face = "bold"),
strip.text = element_text(colour = 'black'),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
axis.text.x = element_text(face="bold", size=12),
axis.text.y = element_text(face="bold", size=12),
axis.ticks.x = element_blank(),
#legend.box.background = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major = element_line(color="gray", size=0.05),
axis.title.x = element_text(size = 14, face = "bold"),
axis.title.y = element_text(size = 14, face = "bold"),
legend.key.height = unit(1, "cm"),
legend.spacing.y = unit(.5, 'cm'),
aspect.ratio=0.8)
pp
ggsave(file.path('~/Downloads/Session_indices_contour_map3.tiff'), pp, dpi = 100)
main = app_data[c('subID','timeDelta_n_sessionsPerDay_no_manipulations', 'timeDelta_avgSessionEntries_no_manipulations','still_valued','devaluation','still_valued_post_deval','mean_still_valued','meanVal_relativeDiff_deval','meanVal_relativeDiff_deval_SQRT','group','training_length')]
colnames(main)[2] = 'timeDelta_n_sessionsPerDay'
colnames(main)[3] = 'timeDelta_avgSessionEntries'
main$training_length[main$training_length=='short'] = -1
main$training_length[main$training_length=='long'] = 1
main$training_length = as.numeric(main$training_length)
main$meanVal_relativeDiff_deval_SQRT = as.numeric(scale(main$meanVal_relativeDiff_deval_SQRT))
main$timeDelta_n_sessionsPerDay = as.numeric(scale(main$timeDelta_n_sessionsPerDay))
main$timeDelta_avgSessionEntries = as.numeric(scale(main$timeDelta_avgSessionEntries))
# rfit does Rank-based estimates for linear models https://rdrr.io/cran/Rfit/man/rfit.html
summary(rf1 <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries*training_length ,data = main))
# testing the interaction effect
summary(rf1_no_3way_inter <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay*training_length ,data = main))
drop.test(rf1,rf1_no_3way_inter) # 3-way interaction is not significant
# testing 2-way interaction effects
summary(rf1_no_n_sessionsPerDay_x_group_int <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_n_sessionsPerDay_x_group_int) # 2-way n_sessionsPerDay_x_group interaction is not significant
summary(rf1_no_avgSessionEntries_x_group_int <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_avgSessionEntries_x_group_int) # 2-way avgSessionEntries_x_group interaction is not significant
summary(rf1_no_n_sessionsPerDay_x_avgSessionEntries <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length +
training_length*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_n_sessionsPerDay_x_avgSessionEntries) # 2-way n_sessionsPerDay_x_avgSessionEntries interaction is not significant
# testing main effects
summary(rf1_main_n_sessionsPerDay <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
summary(rf1_main_avgSessionEntries <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries +
timeDelta_avgSessionEntries:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
summary(rf1_main_training_duration <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*timeDelta_n_sessionsPerDay + training_length:timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
drop.test(rf1,rf1_main_n_sessionsPerDay) # main effect
drop.test(rf1,rf1_main_avgSessionEntries) # main effect
drop.test(rf1,rf1_main_training_duration) # no effect
# --------- Plot:
SDforPlotingSessionIndices = 3
avgEntriesSeq <- seq(min(main$timeDelta_avgSessionEntries), SDforPlotingSessionIndices, by = .05)
avgSessSeq <- seq(min(main$timeDelta_n_sessionsPerDay), SDforPlotingSessionIndices, by = .05)
#avgEntriesSeq <- seq(min(main$timeDelta_avgSessionEntries), max(main$timeDelta_avgSessionEntries), by = .05)
#avgSessSeq <- seq(min(main$timeDelta_n_sessionsPerDay), max(main$timeDelta_n_sessionsPerDay), by = .05)
grSeq <- seq(min(main$training_length), max(main$training_length), by = 2)
habitIndGrid <- expand.grid(timeDelta_avgSessionEntries = avgEntriesSeq, timeDelta_n_sessionsPerDay = avgSessSeq, training_length=grSeq)
habitIndFit = rf1$betahat[1]+
rf1$betahat[2]*habitIndGrid[,'timeDelta_n_sessionsPerDay']+
rf1$betahat[3]*habitIndGrid[,'timeDelta_avgSessionEntries']+
rf1$betahat[4]*habitIndGrid[,'training_length']+
rf1$betahat[5]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'timeDelta_avgSessionEntries']+
rf1$betahat[6]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'training_length']+
rf1$betahat[7]*habitIndGrid[,'timeDelta_avgSessionEntries']*habitIndGrid[,'training_length']+
rf1$betahat[8]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'timeDelta_avgSessionEntries']*habitIndGrid[,'training_length']
# setting values larger than the maximum ("utter goal-directedness") to the maximum
habitIndFit[habitIndFit>max(main$meanVal_relativeDiff_deval_SQRT)] = max(main$meanVal_relativeDiff_deval_SQRT)
# chage names for plotting
habitIndGrid$training_length <- dplyr::recode(habitIndGrid$training_length, "-1" = "Extensive training\n(combined groups)","1" = "Short training")
habitIndGrid$training_length = factor(habitIndGrid$training_length, levels=c('Short training','Extensive training\n(combined groups)'))
main_plot = main
main_plot = main_plot[main_plot$timeDelta_n_sessionsPerDay<SDforPlotingSessionIndices & main_plot$timeDelta_avgSessionEntries<SDforPlotingSessionIndices,]
colnames(main_plot)[9] = 'fit'
main_plot$training_length <- dplyr::recode(main_plot$training_length, "-1" = "Extensive training\n(combined groups)","1" = "Short training")
main_plot$training_length = factor(main_plot$training_length, levels=c('Short training','Extensive training\n(combined groups)'))
# use the scaled variables to get back to the original measures for plotting:
main_plot$fit = main_plot$fit * attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:scale') + attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:center')
main_plot$timeDelta_n_sessionsPerDay = main_plot$timeDelta_n_sessionsPerDay * attr(scaled_timeDelta_n_sessionsPerDay,'scaled:scale') + attr(scaled_timeDelta_n_sessionsPerDay,'scaled:center')
main_plot$timeDelta_avgSessionEntries = main_plot$timeDelta_avgSessionEntries * attr(scaled_timeDelta_avgSessionEntries,'scaled:scale') + attr(scaled_timeDelta_avgSessionEntries,'scaled:center')
habitIndFit = habitIndFit * attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:scale') + attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:center')
habitIndGrid$timeDelta_n_sessionsPerDay = habitIndGrid$timeDelta_n_sessionsPerDay * attr(scaled_timeDelta_n_sessionsPerDay,'scaled:scale') + attr(scaled_timeDelta_n_sessionsPerDay,'scaled:center')
habitIndGrid$timeDelta_avgSessionEntries = habitIndGrid$timeDelta_avgSessionEntries * attr(scaled_timeDelta_avgSessionEntries,'scaled:scale') + attr(scaled_timeDelta_avgSessionEntries,'scaled:center')
p <- ggplot(mutate(habitIndGrid, fit = as.numeric(habitIndFit)),
aes(x = timeDelta_avgSessionEntries, y = timeDelta_n_sessionsPerDay, z = fit)) +
geom_tile(aes(fill = fit)) + geom_contour(binwidth = 0.05) + scale_fill_gradient2(guide = guide_colourbar(title.position = "top",title = "Behavioral\nadaptation\nindex", title.hjust = 0.5)) +
geom_point(aes(fill=fit),main_plot, alpha = 1,shape = 21, colour = "black",size=2) +
#coord_fixed() +
facet_grid(~training_length) +
scale_x_continuous(breaks = breaks_extended(6)) +
ylab('Average # sessions per day')+
xlab('Average # entries per session')
pp <- p + theme_minimal(base_size = 14, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 16, face = "bold"),
strip.text.y = element_text(size = 16, face = "bold"),
strip.text = element_text(colour = 'black'),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
axis.text.x = element_text(face="bold", size=12),
axis.ticks.x = element_blank(),
#legend.box.background = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major = element_line(color="gray", size=0.05),
axis.title.x = element_text(size = 14, face = "bold"),
axis.title.y = element_text(size = 14, face = "bold"),
legend.key.height = unit(1, "cm"),
legend.spacing.y = unit(.5, 'cm'),
aspect.ratio=0.8)
pp
p <- ggplot(mutate(habitIndGrid, fit = as.numeric(habitIndFit)),
aes(x = timeDelta_avgSessionEntries, y = timeDelta_n_sessionsPerDay, z = fit)) +
geom_tile(aes(fill = fit)) + geom_contour() + scale_fill_gradient2(guide = guide_colourbar(title.position = "top",title = "Behavioral\nadaptation\nindex", title.hjust = 0.5)) +
geom_point(aes(fill=fit),main_plot, alpha = 1,shape = 21, colour = "black",size=2) +
#coord_fixed() +
facet_grid(~training_length) +
scale_x_continuous(breaks = breaks_extended(6)) +
xlab('Average # entries per session')+
ylab('Average # sessions per day')
pp <- p + theme_minimal(base_size = 14, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 16, face = "bold"),
strip.text.y = element_text(size = 16, face = "bold"),
strip.text = element_text(colour = 'black'),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
axis.text.x = element_text(face="bold", size=12),
axis.text.y = element_text(face="bold", size=12),
axis.ticks.x = element_blank(),
#legend.box.background = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major = element_line(color="gray", size=0.05),
axis.title.x = element_text(size = 14, face = "bold"),
axis.title.y = element_text(size = 14, face = "bold"),
legend.key.height = unit(1, "cm"),
legend.spacing.y = unit(.5, 'cm'),
aspect.ratio=0.8)
pp
View(long)
main = app_data[c('subID','timeDelta_n_sessionsPerDay', 'timeDelta_avgSessionEntries','still_valued','devaluation','still_valued_post_deval','mean_still_valued','meanVal_relativeDiff_deval','meanVal_relativeDiff_deval_SQRT','group','training_length')]
main$training_length[main$training_length=='short'] = -1
main$training_length[main$training_length=='long'] = 1
main$training_length = as.numeric(main$training_length)
scaled_meanVal_relativeDiff_deval_SQRT = scale(main$meanVal_relativeDiff_deval_SQRT)
main$meanVal_relativeDiff_deval_SQRT = as.numeric(scaled_meanVal_relativeDiff_deval_SQRT)
scaled_timeDelta_n_sessionsPerDay = scale(main$timeDelta_n_sessionsPerDay)
main$timeDelta_n_sessionsPerDay = as.numeric(scaled_timeDelta_n_sessionsPerDay)
scaled_timeDelta_avgSessionEntries = scale(main$timeDelta_avgSessionEntries)
main$timeDelta_avgSessionEntries = as.numeric(scaled_timeDelta_avgSessionEntries)
# rfit does Rank-based estimates for linear models https://rdrr.io/cran/Rfit/man/rfit.html
summary(rf1 <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries*training_length ,data = main))
# testing the interaction effect
summary(rf1_no_3way_inter <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay*training_length ,data = main))
drop.test(rf1,rf1_no_3way_inter) # 3-way interaction is not significant
# testing 2-way interaction effects
summary(rf1_no_n_sessionsPerDay_x_group_int <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_n_sessionsPerDay_x_group_int) # 2-way n_sessionsPerDay_x_group interaction is not significant
summary(rf1_no_avgSessionEntries_x_group_int <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length +
timeDelta_n_sessionsPerDay*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_avgSessionEntries_x_group_int) # 2-way avgSessionEntries_x_group interaction is not significant
summary(rf1_no_n_sessionsPerDay_x_avgSessionEntries <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length +
training_length*timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length
,data = main))
drop.test(rf1,rf1_no_n_sessionsPerDay_x_avgSessionEntries) # 2-way n_sessionsPerDay_x_avgSessionEntries interaction is not significant
# testing main effects
summary(rf1_main_n_sessionsPerDay <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
summary(rf1_main_avgSessionEntries <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_n_sessionsPerDay*training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries +
timeDelta_avgSessionEntries:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
summary(rf1_main_training_duration <- rfit(meanVal_relativeDiff_deval_SQRT ~ timeDelta_avgSessionEntries*timeDelta_n_sessionsPerDay + training_length:timeDelta_avgSessionEntries +
timeDelta_n_sessionsPerDay:training_length + timeDelta_n_sessionsPerDay:timeDelta_avgSessionEntries:training_length ,data = main))
drop.test(rf1,rf1_main_n_sessionsPerDay) # main effect
drop.test(rf1,rf1_main_avgSessionEntries) # main effect
drop.test(rf1,rf1_main_training_duration) # no effect
# --------- Plot:
SDforPlotingSessionIndices = 3
avgEntriesSeq <- seq(min(main$timeDelta_avgSessionEntries), SDforPlotingSessionIndices, by = .02)
avgSessSeq <- seq(min(main$timeDelta_n_sessionsPerDay), SDforPlotingSessionIndices, by = .02)
#avgEntriesSeq <- seq(min(main$timeDelta_avgSessionEntries), max(main$timeDelta_avgSessionEntries), by = .05)
#avgSessSeq <- seq(min(main$timeDelta_n_sessionsPerDay), max(main$timeDelta_n_sessionsPerDay), by = .05)
grSeq <- seq(min(main$training_length), max(main$training_length), by = 2)
habitIndGrid <- expand.grid(timeDelta_avgSessionEntries = avgEntriesSeq, timeDelta_n_sessionsPerDay = avgSessSeq, training_length=grSeq)
habitIndFit = rf1$betahat[1]+
rf1$betahat[2]*habitIndGrid[,'timeDelta_n_sessionsPerDay']+
rf1$betahat[3]*habitIndGrid[,'timeDelta_avgSessionEntries']+
rf1$betahat[4]*habitIndGrid[,'training_length']+
rf1$betahat[5]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'timeDelta_avgSessionEntries']+
rf1$betahat[6]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'training_length']+
rf1$betahat[7]*habitIndGrid[,'timeDelta_avgSessionEntries']*habitIndGrid[,'training_length']+
rf1$betahat[8]*habitIndGrid[,'timeDelta_n_sessionsPerDay']*habitIndGrid[,'timeDelta_avgSessionEntries']*habitIndGrid[,'training_length']
# setting values larger than the maximum ("utter goal-directedness") to the maximum
habitIndFit[habitIndFit>max(main$meanVal_relativeDiff_deval_SQRT)] = max(main$meanVal_relativeDiff_deval_SQRT)
# change names for plotting
habitIndGrid$training_length <- dplyr::recode(habitIndGrid$training_length, "1" = "Extensive training\n(combined groups)","-1" = "Short training")
habitIndGrid$training_length = factor(habitIndGrid$training_length, levels=c('Short training','Extensive training\n(combined groups)'))
main_plot = main
main_plot = main_plot[main_plot$timeDelta_n_sessionsPerDay<SDforPlotingSessionIndices & main_plot$timeDelta_avgSessionEntries<SDforPlotingSessionIndices,]
colnames(main_plot)[9] = 'fit'
main_plot$training_length <- dplyr::recode(main_plot$training_length, "1" = "Extensive training\n(combined groups)","-1" = "Short training")
main_plot$training_length = factor(main_plot$training_length, levels=c('Short training','Extensive training\n(combined groups)'))
# use the scaled variables to get back to the original measures for plotting:
main_plot$fit = main_plot$fit * attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:scale') + attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:center')
main_plot$timeDelta_n_sessionsPerDay = main_plot$timeDelta_n_sessionsPerDay * attr(scaled_timeDelta_n_sessionsPerDay,'scaled:scale') + attr(scaled_timeDelta_n_sessionsPerDay,'scaled:center')
main_plot$timeDelta_avgSessionEntries = main_plot$timeDelta_avgSessionEntries * attr(scaled_timeDelta_avgSessionEntries,'scaled:scale') + attr(scaled_timeDelta_avgSessionEntries,'scaled:center')
habitIndFit = habitIndFit * attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:scale') + attr(scaled_meanVal_relativeDiff_deval_SQRT,'scaled:center')
habitIndGrid$timeDelta_n_sessionsPerDay = habitIndGrid$timeDelta_n_sessionsPerDay * attr(scaled_timeDelta_n_sessionsPerDay,'scaled:scale') + attr(scaled_timeDelta_n_sessionsPerDay,'scaled:center')
habitIndGrid$timeDelta_avgSessionEntries = habitIndGrid$timeDelta_avgSessionEntries * attr(scaled_timeDelta_avgSessionEntries,'scaled:scale') + attr(scaled_timeDelta_avgSessionEntries,'scaled:center')
p <- ggplot(mutate(habitIndGrid, fit = as.numeric(habitIndFit)),
aes(x = timeDelta_avgSessionEntries, y = timeDelta_n_sessionsPerDay, z = fit)) +
geom_tile(aes(fill = fit)) + geom_contour() + scale_fill_gradient2(guide = guide_colourbar(title.position = "top",title = "Behavioral\nadaptation\nindex", title.hjust = 0.5)) +
geom_point(aes(fill=fit),main_plot, alpha = 1,shape = 21, colour = "black",size=2) +
#coord_fixed() +
facet_grid(~training_length) +
scale_x_continuous(breaks = breaks_extended(6)) +
xlab('Average # entries per session')+
ylab('Average # sessions per day')
pp <- p + theme_minimal(base_size = 14, base_family = "Helvetica")+
theme(strip.text.x = element_text(size = 16, face = "bold"),
strip.text.y = element_text(size = 16, face = "bold"),
strip.text = element_text(colour = 'black'),
strip.background = element_rect(color="white", fill="white", linetype="solid"),
axis.text.x = element_text(face="bold", size=12),
axis.text.y = element_text(face="bold", size=12),
axis.ticks.x = element_blank(),
#legend.box.background = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major = element_line(color="gray", size=0.05),
axis.title.x = element_text(size = 14, face = "bold"),
axis.title.y = element_text(size = 14, face = "bold"),
legend.key.height = unit(1, "cm"),
legend.spacing.y = unit(.5, 'cm'),
aspect.ratio=0.8)
pp
main = app_data[c('subID','still_valued','devaluation','still_valued_post_deval','mean_still_valued','group','training_length')]
main$group = as.factor(main$group)
main$training_length = as.factor(main$training_length)
colnames(main)[2:5] = c('pre_val','deval','post_val','mean_val')
main = within(main, group <- relevel(group, ref = 'short_training'))
main = within(main, training_length <- relevel(training_length, ref = 'short'))
main1 = gather(main, manipulation, entries, pre_val:post_val, factor_key=TRUE)
main1 = within(main1, manipulation <- relevel(manipulation, ref = 'pre_val'))
main1 = within(main1, group <- relevel(group, ref = 'short_training'))
main1 = within(main1, training_length <- relevel(training_length, ref = 'short'))
#### Functions to test and adjust Poisson with OVER/UNDERDISPERSSION (http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion)
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
#pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=TRUE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
quasi_table <- function(model,ctab=coef(summary(model)),
phi=overdisp_fun(model)["ratio"]) {
qctab <- within(as.data.frame(ctab),
{   `Std. Error` <- `Std. Error`*sqrt(phi)
`z value` <- Estimate/`Std. Error`
`Pr(>|z|)` <- 2*pnorm(abs(`z value`), lower.tail=FALSE)
})
return(qctab)
}
mX = (glmmTMB(entries ~ manipulation*group + (1|subID), data=main1, family = "nbinom1"))
mX_notInt = (glmmTMB(entries ~ manipulation+group + (1|subID), data=main1, family = "nbinom1"))
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
# --------- create table 1: main regression (NB1) analysis
theme_set(theme_sjplot())
tab_model(mX, transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table 1', file='/Users/ranigera/Downloads/Tab1.html')
tab_model(mX, transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table 1', file='/Users/ranigera/Downloads/Tab1.html')
webshot("/Users/ranigera/Downloads/Tab1.html", "/Users/ranigera/Downloads/Tab1.png")
rm(list=ls())
# load packages (and install them if they are not installed)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(devtools, lme4, lmerTest, rstan, ggplot2, plyr, rstudioapi, car, tidyr, Hmisc, Rfit, R2admb, glmmTMB, glmmADMB,
plotly, flexmix, car, webshot, performance, sjPlot, afex, effectsize, ggpubr, scales, ggpmisc, ggExtra, dplyr)
# set directories and load files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
figures_path  <- ('/Volumes/GoogleDrive/My Drive/Experiments/HAS_STUDY/MS/Figs')
# get and organize the data:
app_data = read.csv('data/extracted_data/all_data_for_R_LargeSample2_FULL_v2.csv', header=T)
# add training_length:
app_data[app_data$group=='short_training','training_length'] = 'short'
app_data[app_data$group!='short_training','training_length'] = 'long'
# separate groups (for some analyses)
short = subset(app_data, training_length=="short")
long = subset(app_data, training_length=="long")
# separate groups (for some analyses)
short_training = subset(app_data, group=="short_training")
long_training = subset(app_data, group=="long_training")
long_training_par = subset(app_data, group=="long_training_parallel_manipulations")
consumption = app_data[c('subID','cave_gold_still_valued','cave_gold_devaluation','cave_gold_still_valued_post_deval','devaluation','group','training_length')]
main = app_data[c('subID','still_valued','devaluation','still_valued_post_deval','mean_still_valued','group','training_length')]
main$group = as.factor(main$group)
main$training_length = as.factor(main$training_length)
colnames(main)[2:5] = c('pre_val','deval','post_val','mean_val')
main = within(main, group <- relevel(group, ref = 'short_training'))
main = within(main, training_length <- relevel(training_length, ref = 'short'))
main1 = gather(main, manipulation, entries, pre_val:post_val, factor_key=TRUE)
main1 = within(main1, manipulation <- relevel(manipulation, ref = 'pre_val'))
main1 = within(main1, group <- relevel(group, ref = 'short_training'))
main1 = within(main1, training_length <- relevel(training_length, ref = 'short'))
#### Functions to test and adjust Poisson with OVER/UNDERDISPERSSION (http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion)
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
#pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=TRUE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
quasi_table <- function(model,ctab=coef(summary(model)),
phi=overdisp_fun(model)["ratio"]) {
qctab <- within(as.data.frame(ctab),
{   `Std. Error` <- `Std. Error`*sqrt(phi)
`z value` <- Estimate/`Std. Error`
`Pr(>|z|)` <- 2*pnorm(abs(`z value`), lower.tail=FALSE)
})
return(qctab)
}
mX = (glmmTMB(entries ~ manipulation*group + (1|subID), data=main1, family = "nbinom2"))
mX_notInt = (glmmTMB(entries ~ manipulation+group + (1|subID), data=main1, family = "nbinom2"))
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
# --------- create table 1: main regression (NB1) analysis
theme_set(theme_sjplot())
tab_model(mX, transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table S1', file='/Users/ranigera/Downloads/Tab1.html')
mX
tab_model(mX)
mX
tab_model(summary(mX), transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table S1', file='/Users/ranigera/Downloads/Tab1.html')
tab_model(mX, transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table S1', file='/Users/ranigera/Downloads/Tab1.html')
main1$obs
# We then tested which of three alternative methods would best fit our data, using Leave-one-out cross-validation (LOOCV).
# We tested an  OLRE (observation-level random effects), in which an "artificial" random effect is added for each observation, negative binomial with a quasi-poisson parameterization σ2=ϕμ, ϕ>1 (NB1) and negative binomial with the classic parameterization with σ2=μ(1+μ/k) (“NB2” in Hardin and Hilbe’s terminology).
# * OLRE - ref: Elston DA, Moss R, Bouliner T, Arrowsmith C, Lambin X. 2001. Analysis of aggregation, a worked example: number of ticks on red grouse. Parasitology 122:563-569
# * nbinom1 and nbinom2 ref: J. W. Hardin and J. M. Hilbe. Generalized Linear Models and Extensions, 2007. [p380]
main1$obs<-seq(nrow(main1)) # add the a unique number per observation for the OLRE
main1$obs
mX = glmmTMB(entries ~ manipulation*group + (1|subID)+(1|obs), data=training_set, family = "poisson")
mX = glmmTMB(entries ~ manipulation*group + (1|subID)+(1|obs), data=training_set, family = "poisson")
# RESULT: the nbinom1 model has the lowest MSE and will be used to test hypotheses 1-3
mX = glmmTMB(entries ~ manipulation*group + (1|subID)+(1|obs), data=main1, family = "poisson")
mX_notInt = glmmTMB(entries ~ manipulation+group + (1|subID)+(1|obs), data=main1, family = "poisson")
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
packages.install
install.packages('sjPlot')
install.packages("sjPlot")
rm(list=ls())
# load packages (and install them if they are not installed)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(devtools, lme4, lmerTest, rstan, ggplot2, plyr, rstudioapi, car, tidyr, Hmisc, Rfit, R2admb, glmmTMB, glmmADMB,
plotly, flexmix, car, webshot, performance, sjPlot, afex, effectsize, ggpubr, scales, ggpmisc, ggExtra, dplyr)
# set directories and load files
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
figures_path  <- ('/Volumes/GoogleDrive/My Drive/Experiments/HAS_STUDY/MS/Figs')
# get and organize the data:
app_data = read.csv('data/extracted_data/all_data_for_R_LargeSample2_FULL_v2.csv', header=T)
# add training_length:
app_data[app_data$group=='short_training','training_length'] = 'short'
app_data[app_data$group!='short_training','training_length'] = 'long'
# separate groups (for some analyses)
short = subset(app_data, training_length=="short")
long = subset(app_data, training_length=="long")
# separate groups (for some analyses)
short_training = subset(app_data, group=="short_training")
long_training = subset(app_data, group=="long_training")
long_training_par = subset(app_data, group=="long_training_parallel_manipulations")
consumption = app_data[c('subID','cave_gold_still_valued','cave_gold_devaluation','cave_gold_still_valued_post_deval','devaluation','group','training_length')]
main = app_data[c('subID','still_valued','devaluation','still_valued_post_deval','mean_still_valued','group','training_length')]
main$group = as.factor(main$group)
main$training_length = as.factor(main$training_length)
colnames(main)[2:5] = c('pre_val','deval','post_val','mean_val')
main = within(main, group <- relevel(group, ref = 'short_training'))
main = within(main, training_length <- relevel(training_length, ref = 'short'))
main1 = gather(main, manipulation, entries, pre_val:post_val, factor_key=TRUE)
main1 = within(main1, manipulation <- relevel(manipulation, ref = 'pre_val'))
main1 = within(main1, group <- relevel(group, ref = 'short_training'))
main1 = within(main1, training_length <- relevel(training_length, ref = 'short'))
#### Functions to test and adjust Poisson with OVER/UNDERDISPERSSION (http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion)
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
#pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=TRUE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
quasi_table <- function(model,ctab=coef(summary(model)),
phi=overdisp_fun(model)["ratio"]) {
qctab <- within(as.data.frame(ctab),
{   `Std. Error` <- `Std. Error`*sqrt(phi)
`z value` <- Estimate/`Std. Error`
`Pr(>|z|)` <- 2*pnorm(abs(`z value`), lower.tail=FALSE)
})
return(qctab)
}
mX = (glmmTMB(entries ~ manipulation*group + (1|subID), data=main1, family = "nbinom2"))
mX_notInt = (glmmTMB(entries ~ manipulation+group + (1|subID), data=main1, family = "nbinom2"))
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
# --------- create table 1: main regression (NB1) analysis
theme_set(theme_sjplot())
tab_model(mX, transform = NULL, show.se=TRUE, show.ci = FALSE,wrap.labels = 100,
dv.labels = 'Entries', pred.labels=c('(Intercept)','Manipulation [Devaluation]','Manipulation [Control - post]',
'Group [Extensive Training]','Group [Extensive Training - Parallel week1 manipulations]',
'Manipulation [Devaluation] * Group [Extensive Training]','Manipulation [Control - post] * Group [Extensive Training]',
'Manipulation [Devaluation] * Group [Extensive Training - Parallel week1 manipulations]','Manipulation [Control - post] * Group [Extensive Training - Parallel week1 manipulations]'),
show.r2=FALSE, show.icc=FALSE, show.zeroinf=FALSE, show.ngroups=FALSE,
show.obs = FALSE, show.re.var=FALSE, title='Table S1', file='/Users/ranigera/Downloads/TabS2.html')
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
mX = (glmmTMB(entries ~ manipulation*group + (1|subID), data=main1, family = "nbinom2"))
mX_notInt = (glmmTMB(entries ~ manipulation+group + (1|subID), data=main1, family = "nbinom2"))
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
main1$obs<-seq(nrow(main1)) # add the a unique number per observation for the OLRE
# RESULT: the nbinom1 model has the lowest MSE and will be used to test hypotheses 1-3
mX = glmmTMB(entries ~ manipulation*group + (1|subID)+(1|obs), data=main1, family = "poisson")
mX_notInt = glmmTMB(entries ~ manipulation+group + (1|subID)+(1|obs), data=main1, family = "poisson")
summary(mX)
anova(mX,mX_notInt) # testing the interaction effect
Anova(mX,type=3) # If wanting to check the estimated main effects. (see this: https://stats.stackexchange.com/questions/60362/choice-between-type-i-type-ii-or-type-iii-anova and https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova)
rm(list=ls())
# load libraries
if (!require("pacman")) install.packages("pacman")
pacman::p_load(flexmix, plotrix, scales, rstudioapi,effectsize, car, lme4, lmerTest, pbkrtest, ggplot2, dplyr, plyr, tidyr, multcomp, mvoutlier, HH, doBy, psych, pastecs, reshape, reshape2,
jtools, effects, compute.es, DescTools, MBESS, afex, ez, metafor, influence.ME, GPArotation, SparkR, emmeans, afex, ntile, ggpubr,lattice)
# Set path
home_path <- dirname(getActiveDocumentContext()$path)
data_base_file <- file.path(home_path,'my_databases/txt_data/presses_HIS_May_2022.csv')
ratings_data <- file.path(home_path,'my_databases/txt_data/food_liking_HIS_May_2022.txt')
figures_path    <- file.path(home_path,'figures')
clustered_data_file <- file.path(home_path,'my_databases/txt_data/clustered_subgroups_HIS_May_2022.csv')
setwd (home_path)
# get database
FULL <- read.csv(data_base_file, header=TRUE, sep=",")
RATINGS=read.delim(ratings_data, header = TRUE, sep = "\t")
# remove the baseline condition from the data
FULL <- subset(FULL, VALUE == 'valued' | VALUE == 'devalued')
# define factors
FULL$ID        <- factor(FULL$ID)
FULL$GROUP     <- factor(FULL$GROUP)
FULL$VALUE     <- factor(FULL$VALUE)
RATINGS$ID     <- factor(RATINGS$ID)
RATINGS$group  <- factor(RATINGS$group)
RATINGS$value  <- factor(RATINGS$value)
RATINGS$time   <- factor(RATINGS$time)
# define factors
FULL$ID        <- factor(FULL$ID)
group_by(FULL, ID)
